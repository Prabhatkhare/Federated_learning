# -*- coding: utf-8 -*-
"""Base_ppr_final_updated2.0

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f4kpGYq8-NegcDnHdWVYHhtzL2htozwC
"""

# -*- coding: utf-8 -*-
"""base_paper_with_val_test_and_timing"""

import copy
import time
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import models, transforms, datasets
from torch.utils.data import DataLoader, Subset, random_split, ConcatDataset
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import pandas as pd
import logging
import os

# ----------------------------
# Config
# ----------------------------
NUM_CLIENTS = 3
NUM_ROUNDS = 2           # quick test; change to 200 for full
LOCAL_EPOCHS = 2
BATCH_SIZE = 8
LR = 1e-4                 # from paper
MU = 1.0
TAU = 0.5
PROJ_DIM = 56
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
BETA = 0.5                # Dirichlet split parameter

# ----------------------------
# Paths
# ----------------------------
DATASET_PATH = "/content/drive/MyDrive/dataset_mini"
LOG_FILE = "training.log"
EXCEL_FILE = "results.xlsx"

# ----------------------------
# Logging setup
# ----------------------------
logging.basicConfig(
    filename=LOG_FILE,
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    filemode="w"
)

# Results list
results = []

# ----------------------------
# Data transforms
# ----------------------------
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

# ----------------------------
# Dirichlet Non-IID split
# ----------------------------
def dirichlet_split(dataset, num_clients, beta):
    labels = np.array([dataset[i][1] for i in range(len(dataset))])
    label_set = set(labels)
    idx_list = [[] for _ in range(num_clients)]
    for label in label_set:
        label_indices = np.where(labels == label)[0]
        np.random.shuffle(label_indices)
        proportions = np.random.dirichlet(np.repeat(beta, num_clients))
        proportions = (np.cumsum(proportions) * len(label_indices)).astype(int)[:-1]
        split_indices = np.split(label_indices, proportions)
        for cid, idxs in enumerate(split_indices):
            idx_list[cid].extend(idxs)
    client_datasets = [Subset(dataset, idxs) for idxs in idx_list]
    return client_datasets

# ----------------------------
# Model (DenseNet121 with proj_dim=56)
# ----------------------------
class DenseNetFedCL(nn.Module):
    def __init__(self, num_classes, proj_dim=56):
        super(DenseNetFedCL, self).__init__()
        backbone = models.densenet121(pretrained=False)
        num_ftrs = backbone.classifier.in_features
        backbone.classifier = nn.Identity()
        self.backbone = backbone
        self.proj_head = nn.Sequential(
            nn.Linear(num_ftrs, proj_dim),
            nn.ReLU(),
            nn.Linear(proj_dim, proj_dim)
        )
        self.classifier = nn.Linear(num_ftrs, num_classes)

    def forward(self, x, return_features=False):
        feats = self.backbone(x)
        proj_feats = self.proj_head(feats)
        out = self.classifier(feats)
        if return_features:
            return out, proj_feats, feats
        else:
            return out

# ----------------------------
# Contrastive Loss
# ----------------------------
def supervised_contrastive_loss(v_local, v_prev_global, v_prev_local, tau=TAU):
    v_local = F.normalize(v_local, p=2, dim=-1)
    v_prev_global = F.normalize(v_prev_global, p=2, dim=-1)
    v_prev_local = F.normalize(v_prev_local, p=2, dim=-1)
    sim_global = torch.sum(v_local * v_prev_global, dim=-1) / tau
    sim_local = torch.sum(v_local * v_prev_local, dim=-1) / tau
    numerator = torch.exp(sim_global)
    denominator = numerator + torch.exp(sim_local)
    loss = -torch.log(numerator / (denominator + 1e-8))
    return loss.mean()

# ----------------------------
# Local training
# ----------------------------
def local_fedcl_train(model, prev_global_model, prev_local_model, train_loader, optimizer, mu=MU, device=DEVICE):
    model.train()
    prev_global_model.eval()
    prev_local_model.eval()
    criterion = nn.CrossEntropyLoss()
    for epoch in range(LOCAL_EPOCHS):
        for imgs, labels in train_loader:
            imgs, labels = imgs.to(device), labels.to(device)
            optimizer.zero_grad()
            with torch.no_grad():
                prev_global_model.to(device)
                prev_local_model.to(device)
                _, v_prev_global, _ = prev_global_model(imgs, return_features=True)
                _, v_prev_local, _ = prev_local_model(imgs, return_features=True)
            _, v_local, logits = model(imgs, return_features=True)
            ce_loss = criterion(logits, labels)
            scl = supervised_contrastive_loss(v_local, v_prev_global, v_prev_local)
            total_loss = ce_loss + mu * scl
            total_loss.backward()
            optimizer.step()
    return model

# ----------------------------
# Aggregation
# ----------------------------
def aggregate_models(global_model, client_models, client_sizes):
    total = sum(client_sizes)
    new_state = copy.deepcopy(global_model.state_dict())
    for key in new_state.keys():
        new_state[key] = sum([client_models[i].state_dict()[key] * (client_sizes[i] / total)
                              for i in range(len(client_models))])
    global_model.load_state_dict(new_state)
    return global_model

# ----------------------------
# Evaluation
# ----------------------------
def evaluate_model(model, data_loader, device=DEVICE):
    model.eval()
    all_labels, all_preds = [], []
    with torch.no_grad():
        for imgs, labels in data_loader:
            imgs = imgs.to(device)
            outputs = model(imgs)
            preds = torch.argmax(outputs, dim=1).cpu().numpy()
            all_preds.extend(preds)
            all_labels.extend(labels.numpy())
    acc = accuracy_score(all_labels, all_preds)
    prec = precision_score(all_labels, all_preds, average='macro', zero_division=0)
    rec = recall_score(all_labels, all_preds, average='macro', zero_division=0)
    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)
    return acc, prec, rec, f1

# ----------------------------
# Main
# ----------------------------
def main():
    # Load dataset
    full_dataset = datasets.ImageFolder(DATASET_PATH, transform=transform)
    num_classes = len(full_dataset.classes)

    # Split into train (70%), val (10%), test (20%)
    n_total = len(full_dataset)
    n_train = int(0.7 * n_total)
    n_val = int(0.1 * n_total)
    n_test = n_total - n_train - n_val
    train_set, val_set, test_set = random_split(full_dataset, [n_train, n_val, n_test])

    val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)
    test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)

    # Split train set into clients (Dirichlet)
    client_datasets = dirichlet_split(train_set, NUM_CLIENTS, BETA)
    client_loaders = [DataLoader(ds, batch_size=BATCH_SIZE, shuffle=True) for ds in client_datasets]

    # Log client dataset sizes
    for cid, ds in enumerate(client_datasets):
        logging.info(f"Client {cid+1} has {len(ds)} images")

    # Init models
    global_model = DenseNetFedCL(num_classes=num_classes, proj_dim=PROJ_DIM).to(DEVICE)
    prev_global_model = copy.deepcopy(global_model).eval()
    prev_local_models = [copy.deepcopy(global_model).eval() for _ in range(NUM_CLIENTS)]

    for rnd in range(1, NUM_ROUNDS + 1):
        print(f"\n--- Round {rnd} ---")
        logging.info(f"--- Round {rnd} ---")

        client_models, client_sizes = [], []

        # Train each client
        for cid in range(NUM_CLIENTS):
            start_time = time.time()
            local_model = copy.deepcopy(global_model).to(DEVICE)
            optimizer = torch.optim.Adam(local_model.parameters(), lr=LR)
            local_model = local_fedcl_train(local_model, prev_global_model, prev_local_models[cid],
                                            client_loaders[cid], optimizer)
            elapsed = time.time() - start_time
            client_models.append(local_model)
            client_sizes.append(len(client_datasets[cid]))

            # Save client metrics
            acc, prec, rec, f1 = evaluate_model(global_model, client_loaders[cid])
            msg = f"Client {cid+1} -> Size: {len(client_datasets[cid])}, Time: {elapsed:.2f}s, Acc: {acc:.4f}, Prec: {prec:.4f}, Rec: {rec:.4f}, F1: {f1:.4f}"
            print(msg)
            logging.info(msg)
            results.append({
                "Round": rnd,
                "Client": cid + 1,
                "Images": len(client_datasets[cid]),
                "Train_Time(s)": elapsed,
                "Accuracy": acc,
                "Precision": prec,
                "Recall": rec,
                "F1": f1,
                "Type": "Client"
            })

        # Aggregate
        start_time = time.time()
        global_model = aggregate_models(global_model, client_models, client_sizes)
        agg_time = time.time() - start_time

        # Update prev models
        prev_global_model = copy.deepcopy(global_model).eval()
        prev_local_models = [copy.deepcopy(client_models[cid]).eval() for cid in range(NUM_CLIENTS)]

        # Validate on centralized validation set
        v_acc, v_prec, v_rec, v_f1 = evaluate_model(global_model, val_loader)
        results.append({
            "Round": rnd,
            "Client": "Validation",
            "Images": len(val_set),
            "Train_Time(s)": 0,
            "Accuracy": v_acc,
            "Precision": v_prec,
            "Recall": v_rec,
            "F1": v_f1,
            "Type": "Validation"
        })

        # Global evaluation on merged client data
        merged_loader = DataLoader(ConcatDataset(client_datasets), batch_size=BATCH_SIZE, shuffle=False)
        g_acc, g_prec, g_rec, g_f1 = evaluate_model(global_model, merged_loader)
        msg = f"Global Model -> AggTime: {agg_time:.2f}s, Acc: {g_acc:.4f}, Prec: {g_prec:.4f}, Rec: {g_rec:.4f}, F1: {g_f1:.4f}"
        print(msg)
        logging.info(msg)
        results.append({
            "Round": rnd,
            "Client": "Global",
            "Images": sum(client_sizes),
            "Train_Time(s)": agg_time,
            "Accuracy": g_acc,
            "Precision": g_prec,
            "Recall": g_rec,
            "F1": g_f1,
            "Type": "Global"
        })

    # Final test evaluation
    t_acc, t_prec, t_rec, t_f1 = evaluate_model(global_model, test_loader)
    results.append({
        "Round": "Final",
        "Client": "Test",
        "Images": len(test_set),
        "Train_Time(s)": 0,
        "Accuracy": t_acc,
        "Precision": t_prec,
        "Recall": t_rec,
        "F1": t_f1,
        "Type": "Test"
    })
    print(f"\nFinal Test -> Acc: {t_acc:.4f}, Prec: {t_prec:.4f}, Rec: {t_rec:.4f}, F1: {t_f1:.4f}")

    # Save results to Excel
    df = pd.DataFrame(results)
    df.to_excel(EXCEL_FILE, index=False)
    print(f"\nResults saved to {EXCEL_FILE}")
    logging.info(f"Results saved to {EXCEL_FILE}")
    print(f"Logs saved to {LOG_FILE}")

if __name__ == "__main__":
    main()